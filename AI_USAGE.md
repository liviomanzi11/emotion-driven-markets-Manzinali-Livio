# AI Tools Usage Documentation

**Project:** Emotion-Driven Markets  
**Author:** Livio Manzinali  
**Course:** DSAP Fall 2025

## Overview

This document describes how AI tools were used throughout the project development, following the course policy on responsible AI assistance.

## Tools Used

### 1. GitHub Copilot
**Purpose:** Code autocompletion and boilerplate generation  
**Usage frequency:** Moderate (30-40% of code)

**Examples:**
- Autocomplete for pandas data manipulation patterns
- Standard sklearn model training templates
- Docstring generation for functions
- Common data cleaning operations

**Review process:** All suggestions manually reviewed and adapted to project needs

### 2. ChatGPT (GPT-4)
**Purpose:** Debugging, documentation, and conceptual help  
**Usage frequency:** Regular (for specific problems)

**Examples:**
- Debugging TensorFlow/Keras reproducibility issues
- Understanding FinBERT model architecture
- Clarifying sklearn API documentation
- Generating initial README structure
- Troubleshooting environment setup errors

**Review process:** All generated code tested and modified for project context

### 3. Claude (Anthropic)
**Purpose:** Code review and architecture discussions  
**Usage frequency:** Occasional

**Examples:**
- Reviewing feature engineering logic
- Discussing backtest strategy implementation
- Code quality improvements
- Project structure organization

## What AI Did NOT Do

- **Research design:** Problem formulation and methodology were my own
- **Data analysis:** All interpretation of results is original
- **Critical decisions:** Model selection, hyperparameters, feature choices
- **Report writing:** Analysis, discussion, and conclusions are my work
- **Algorithm design:** Core logic for backtesting and strategies

## Learning Outcomes

Using AI tools helped me:
1. **Focus on high-level design** rather than syntax details
2. **Learn new libraries faster** (e.g., TensorFlow determinism)
3. **Debug efficiently** by getting suggestions for error patterns
4. **Write better documentation** through initial templates

However, I ensured:
- **Full understanding** of all code in the final submission
- **Manual validation** of AI suggestions against documentation
- **Original problem-solving** for core project challenges
- **Independent debugging** when AI suggestions failed


## Conclusion

AI tools served as **productivity assistants**, not replacements for learning. They accelerated implementation but did not substitute for understanding the underlying concepts, data science principles, or project-specific decision-making.

---

*Date: December 1, 2025*
